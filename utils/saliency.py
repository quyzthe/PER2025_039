# saliency.py
import cv2
import numpy as np
from skimage.color import rgb2lab, gray2rgb
from skimage.io import imread
from skimage.transform import rescale

# ------------------------
# Spectral Residual Saliency
# ------------------------
def spectral_residual_saliency(img, width=128):
    """
    Compute saliency map using Spectral Residual method.
    Input:
        img: RGB image as numpy array
        width: resize width for computation
    Output:
        saliency_map: float32 numpy array normalized [0,1]
    """
    # Convert to grayscale
    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    h, w = img_gray.shape
    new_h = int(width * h / w)
    img_resized = cv2.resize(img_gray, (width, new_h))

    # Fourier Transform
    c = cv2.dft(np.float32(img_resized), flags=cv2.DFT_COMPLEX_OUTPUT)
    mag = np.sqrt(c[:,:,0]**2 + c[:,:,1]**2)

    # Spectral Residual
    log_mag = np.log(mag + 1e-8)
    avg_log_mag = cv2.boxFilter(log_mag, -1, (3,3))
    spectral_residual = np.exp(log_mag - avg_log_mag)

    # Apply residual to original complex
    c[:,:,0] = c[:,:,0] * spectral_residual / (mag + 1e-8)
    c[:,:,1] = c[:,:,1] * spectral_residual / (mag + 1e-8)

    # Inverse Fourier
    c_inv = cv2.dft(c, flags=(cv2.DFT_INVERSE | cv2.DFT_SCALE))
    sal_map = c_inv[:,:,0]**2 + c_inv[:,:,1]**2

    # Gaussian smoothing and normalization
    sal_map = cv2.GaussianBlur(sal_map, (9,9), 3)
    sal_map = cv2.normalize(sal_map, None, 0., 1., cv2.NORM_MINMAX)

    return sal_map


# ------------------------
# BMS Saliency
# ------------------------
N_THRESHOLDS = 10

def activate_boolean_map(bool_map):
    activation = np.array(bool_map, dtype=np.uint8)
    mask_shape = (bool_map.shape[0] + 2, bool_map.shape[1] + 2)
    ffill_mask = np.zeros(mask_shape, dtype=np.uint8)

    for i in range(activation.shape[0]):
        for j in [0, activation.shape[1]-1]:
            if activation[i,j]:
                cv2.floodFill(activation, ffill_mask, (j,i), 0)
    for i in [0, activation.shape[0]-1]:
        for j in range(activation.shape[1]):
            if activation[i,j]:
                cv2.floodFill(activation, ffill_mask, (j,i), 0)
    return activation

def compute_bms_saliency(img):
    """
    Compute Boolean Map Saliency (BMS) for RGB image.
    Input:
        img: RGB image as numpy array
    Output:
        attn_map: uint8 saliency map [0,255]
    """
    img_lab = rgb2lab(img)
    img_lab -= img_lab.min()
    img_lab /= img_lab.max()
    thresholds = np.arange(0, 1, 1.0 / N_THRESHOLDS)[1:]

    bool_maps = []
    for thresh in thresholds:
        img_lab_T = img_lab.transpose(2,0,1)
        img_thresh = (img_lab_T > thresh)
        bool_maps.extend(list(img_thresh))

    attn_map = np.zeros(img_lab.shape[:2], dtype=np.float32)
    for bmap in bool_maps:
        attn_map += activate_boolean_map(bmap)
    attn_map /= N_THRESHOLDS

    # Gaussian smoothing
    attn_map = cv2.GaussianBlur(attn_map, (0,0), 3)
    
    # Normalize to [0,255]
    norm = np.sqrt((attn_map**2).sum())
    attn_map /= (norm + 1e-8)
    attn_map /= attn_map.max() / 255

    return attn_map.astype(np.uint8)


# ------------------------
# Helper: Load Image
# ------------------------
def load_rgb_image(img_path, max_dim=320):
    img = imread(img_path)
    if img.ndim == 2:
        img = gray2rgb(img)
    elif img.shape[2] == 4:
        img = img[:,:,:3]
    upper_dim = max(img.shape[:2])
    if upper_dim > max_dim:
        img = rescale(img, max_dim/float(upper_dim), order=3, anti_aliasing=True, channel_axis=-1)
        img = (img * 255).astype(np.uint8)
    return img


def apply_center_surround(img, sigma_center=1.0, sigma_surround=3.0, strength=1.0):
    """
    Apply Center-Surround filter using Difference of Gaussians (DoG).
    This mimics the retinal ganglion cells: enhancing edges and local contrast.
    
    Input:
        img: Grayscale or RGB image (numpy array)
        sigma_center: Standard deviation for the center Gaussian (excitatory)
        sigma_surround: Standard deviation for the surround Gaussian (inhibitory)
        strength: Factor to control the intensity of the filter
    Output:
        cs_img: Filtered image
    """
    # Ensure image is float for calculation
    img_float = img.astype(np.float32) / 255.0
    
    # Calculate Center (Excitatory)
    center = cv2.GaussianBlur(img_float, (0, 0), sigma_center)
    
    # Calculate Surround (Inhibitory)
    surround = cv2.GaussianBlur(img_float, (0, 0), sigma_surround)
    
    # DoG: Center - Surround
    dog = center - surround
    
    # Normalize or clip to keep within valid range if needed, 
    # but usually we want to keep the positive/negative responses for further processing.
    # For visualization/compatibility, we often add 0.5 or clip.
    # Here we return the raw DoG response enhanced by strength.
    cs_img = dog * strength
    
    # If you need a viewable image (0-255), you might want to normalize:
    # cs_view = cv2.normalize(cs_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    
    return cs_img

def spectral_residual_saliency_with_cs(img, width=128):
    # 1. Convert to grayscale
    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    
    # --- ÁP DỤNG CS FILTER Ở ĐÂY ---
    # CS filter giúp làm nổi bật các cạnh và chi tiết tần số cao
    # Thay vì dùng ảnh xám gốc, ta dùng ảnh đã qua lọc DoG
    img_cs = apply_center_surround(img_gray, sigma_center=2, sigma_surround=8)
    
    # Vì Fourier cần đầu vào dương để log, ta cần chuẩn hóa lại về [0, 1] hoặc [0, 255]
    img_cs_norm = cv2.normalize(img_cs, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    # -------------------------------

    h, w = img_gray.shape
    new_h = int(width * h / w)
    img_resized = cv2.resize(img_cs_norm, (width, new_h)) # Dùng ảnh đã lọc CS

    # Fourier Transform
    c = cv2.dft(np.float32(img_resized), flags=cv2.DFT_COMPLEX_OUTPUT)
    mag = np.sqrt(c[:,:,0]**2 + c[:,:,1]**2)

    # Spectral Residual
    log_mag = np.log(mag + 1e-8)
    avg_log_mag = cv2.boxFilter(log_mag, -1, (3,3))
    spectral_residual = np.exp(log_mag - avg_log_mag)

    # Apply residual to original complex
    c[:,:,0] = c[:,:,0] * spectral_residual / (mag + 1e-8)
    c[:,:,1] = c[:,:,1] * spectral_residual / (mag + 1e-8)

    # Inverse Fourier
    c_inv = cv2.dft(c, flags=(cv2.DFT_INVERSE | cv2.DFT_SCALE))
    sal_map = c_inv[:,:,0]**2 + c_inv[:,:,1]**2

    # Gaussian smoothing and normalization
    sal_map = cv2.GaussianBlur(sal_map, (9,9), 3)
    sal_map = cv2.normalize(sal_map, None, 0., 1., cv2.NORM_MINMAX)

    return sal_map


def compute_bms_saliency_with_cs(img):
    img_lab = rgb2lab(img)
    
    # --- ÁP DỤNG CS FILTER CHO TỪNG KÊNH MÀU ---
    # Tăng cường tương phản màu cục bộ
    for i in range(3): # Loop qua L, a, b
        channel = img_lab[:,:,i]
        # Chuyển về scale 0-255 tạm thời để khớp tham số hàm CS
        ch_norm = cv2.normalize(channel, None, 0, 255, cv2.NORM_MINMAX)
        
        # Áp dụng CS: Center (nhỏ) - Surround (lớn)
        cs_response = apply_center_surround(ch_norm, sigma_center=3, sigma_surround=10)
        
        # Cộng phản hồi CS vào kênh gốc để tăng cường (hoặc thay thế tùy chiến lược)
        # Ở đây ta chọn cách cộng để làm nổi bật feature
        img_lab[:,:,i] += cs_response * 5.0 # *5 để tăng trọng số hiệu ứng
    # ---------------------------------------------

    img_lab -= img_lab.min()
    img_lab /= img_lab.max() # Normalize lại về [0, 1]
    
    thresholds = np.arange(0, 1, 1.0 / N_THRESHOLDS)[1:]

    bool_maps = []
    for thresh in thresholds:
        img_lab_T = img_lab.transpose(2,0,1)
        img_thresh = (img_lab_T > thresh)
        bool_maps.extend(list(img_thresh))

    attn_map = np.zeros(img_lab.shape[:2], dtype=np.float32)
    for bmap in bool_maps:
        attn_map += activate_boolean_map(bmap)
    attn_map /= N_THRESHOLDS

    # Gaussian smoothing
    attn_map = cv2.GaussianBlur(attn_map, (0,0), 3)
    
    # Normalize to [0,255]
    norm = np.sqrt((attn_map**2).sum())
    attn_map /= (norm + 1e-8)
    attn_map /= attn_map.max() / 255

    return attn_map.astype(np.uint8)



import cv2
import numpy as np
from skimage.color import rgb2lab, gray2rgb
from skimage.io import imread
from skimage.transform import rescale

# =============================================================================
# Helper Functions: Filters & Morphology
# =============================================================================

def apply_center_surround_filter(img, sigma_center=1.0, sigma_surround=3.0, strength=1.0):
    """
    Apply Center-Surround filter (DoG) to enhance edges and local contrast.
    This mimics retinal ganglion cells.
    
    Input:
        img: Grayscale or single channel image (numpy array), uint8 or float.
    Output:
        cs_img: Filtered image, normalized to [0, 1].
    """
    # Ensure image is float32 for calculation
    if img.dtype != np.float32:
        img_float = img.astype(np.float32) / 255.0
    else:
        img_float = img

    # Center (Excitatory)
    center = cv2.GaussianBlur(img_float, (0, 0), sigma_center)
    
    # Surround (Inhibitory)
    surround = cv2.GaussianBlur(img_float, (0, 0), sigma_surround)
    
    # DoG = Center - Surround
    dog = (center - surround) * strength
    
    # For edge enhancement, take absolute value to capture both ON/OFF edges
    cs_img = np.abs(dog)
    
    return np.clip(cs_img, 0, 1)


def apply_hollow_filling(saliency_map, kernel_size=5):
    """
    Apply Morphological Closing and Filling to fill hollow regions
    typically caused by edge-only data (e.g., event cameras).
    
    Input:
        saliency_map: Saliency map (float 0-1 or uint8 0-255)
    Output:
        filled_map: Processed map with filled regions.
    """
    # Convert to uint8 for morphology operations
    if saliency_map.dtype != np.uint8:
        # Assuming float input is 0-1
        s_uint8 = (saliency_map * 255).astype(np.uint8)
    else:
        s_uint8 = saliency_map.copy()

    # 1. Morphological Closing: Dilate then Erode to close gaps in contours
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    closed = cv2.morphologyEx(s_uint8, cv2.MORPH_CLOSE, kernel)
    
    # 2. Contour Filling: Find contours and fill them
    # Threshold to get binary mask of potential objects
    # Adjust threshold (e.g., 50) based on your data sensitivity
    _, binary = cv2.threshold(closed, 50, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    filled = np.zeros_like(s_uint8)
    # Fill inside external contours
    cv2.drawContours(filled, contours, -1, 255, thickness=cv2.FILLED)
    
    # Blend filled mask with original saliency: use max to keep strong signals
    result_uint8 = cv2.max(s_uint8, filled)
    
    # Return in the same format as input
    if saliency_map.dtype != np.uint8:
        return result_uint8.astype(np.float32) / 255.0
    return result_uint8


def load_and_preprocess_image(img_path, max_dim=320):
    """
    Load RGB image and resize it maintaining aspect ratio.
    """
    img = imread(img_path)
    if img.ndim == 2:
        img = gray2rgb(img)
    elif img.shape[2] == 4:
        img = img[:,:,:3]
        
    upper_dim = max(img.shape[:2])
    if upper_dim > max_dim:
        scale = max_dim / float(upper_dim)
        img = rescale(img, scale, order=3, anti_aliasing=True, channel_axis=-1)
        img = (img * 255).astype(np.uint8)
    return img


# =============================================================================
# Method 1: Spectral Residual Saliency (Enhanced)
# =============================================================================

def spectral_residual_saliency_v2(img, width=128, enable_cs=True, enable_fill=True):
    """
    Compute saliency map using Spectral Residual method with optional enhancements.
    
    Args:
        img: RGB image (numpy array).
        width: Calculation width.
        enable_cs: Enable Center-Surround filtering (pre-processing).
        enable_fill: Enable morphological filling for hollow objects (post-processing).
    """
    # Convert to grayscale
    if img.ndim == 3:
        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    else:
        img_gray = img

    # --- Pre-processing: Center-Surround ---
    if enable_cs:
        # Apply CS filter to enhance edges
        cs_response = apply_center_surround_filter(img_gray, sigma_center=2, sigma_surround=8, strength=2.0)
        # Use the enhanced edge image for SR calculation
        img_input = (cs_response * 255).astype(np.uint8)
    else:
        img_input = img_gray

    # Resize for efficiency
    h, w = img_input.shape
    new_h = int(width * h / w)
    img_resized = cv2.resize(img_input, (width, new_h))

    # --- Core Algorithm: Spectral Residual ---
    # Fourier Transform
    c = cv2.dft(np.float32(img_resized), flags=cv2.DFT_COMPLEX_OUTPUT)
    mag = np.sqrt(c[:,:,0]**2 + c[:,:,1]**2)

    # Spectral Residual Calculation
    log_mag = np.log(mag + 1e-8)
    avg_log_mag = cv2.boxFilter(log_mag, -1, (3,3))
    spectral_residual = np.exp(log_mag - avg_log_mag)

    # Reconstruct with residual magnitude
    c[:,:,0] = c[:,:,0] * spectral_residual / (mag + 1e-8)
    c[:,:,1] = c[:,:,1] * spectral_residual / (mag + 1e-8)

    # Inverse Fourier
    c_inv = cv2.dft(c, flags=(cv2.DFT_INVERSE | cv2.DFT_SCALE))
    sal_map = c_inv[:,:,0]**2 + c_inv[:,:,1]**2

    # Smoothing and Normalization
    sal_map = cv2.GaussianBlur(sal_map, (9,9), 3)
    sal_map = cv2.normalize(sal_map, None, 0., 1., cv2.NORM_MINMAX)

    # --- Post-processing: Hollow Filling ---
    if enable_fill:
        sal_map = apply_hollow_filling(sal_map, kernel_size=5)

    return sal_map


# =============================================================================
# Method 2: Boolean Map Saliency (BMS) (Enhanced)
# =============================================================================

N_THRESHOLDS = 10

def _activate_boolean_map_helper(bool_map):
    """Internal helper for BMS to process boolean maps."""
    activation = np.array(bool_map, dtype=np.uint8)
    mask_shape = (bool_map.shape[0] + 2, bool_map.shape[1] + 2)
    ffill_mask = np.zeros(mask_shape, dtype=np.uint8)

    # Flood fill from borders to ignore background
    # Top and Bottom
    for j in range(activation.shape[1]):
        if activation[0, j]:
            cv2.floodFill(activation, ffill_mask, (j, 0), 0)
        if activation[activation.shape[0]-1, j]:
            cv2.floodFill(activation, ffill_mask, (j, activation.shape[0]-1), 0)
    
    # Left and Right
    for i in range(activation.shape[0]):
        if activation[i, 0]:
            cv2.floodFill(activation, ffill_mask, (0, i), 0)
        if activation[i, activation.shape[1]-1]:
            cv2.floodFill(activation, ffill_mask, (activation.shape[1]-1, i), 0)
            
    return activation


def compute_bms_saliency_v2(img, enable_cs=True, enable_fill=True):
    """
    Compute Boolean Map Saliency (BMS) with optional enhancements.
    
    Args:
        img: RGB image (numpy array).
        enable_cs: Enable Center-Surround filtering on Lab channels.
        enable_fill: Enable morphological filling for hollow objects.
    """
    img_lab = rgb2lab(img)
    
    # --- Pre-processing: Center-Surround on Color Channels ---
    if enable_cs:
        # Apply CS to each channel (L, a, b) to enhance local color contrast
        for i in range(3):
            # Normalize channel to 0-255 for CS filter
            ch_norm = cv2.normalize(img_lab[:,:,i], None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
            
            # Apply filter
            cs_resp = apply_center_surround_filter(ch_norm, sigma_center=2, sigma_surround=6, strength=1.5)
            
            # Add CS response back to channel to boost prominent features
            # Weight 10.0 allows the edge signal to influence the thresholding significantly
            img_lab[:,:,i] += cs_resp * 10.0 
    
    # Normalize Lab image for thresholding
    img_lab -= img_lab.min()
    img_lab /= (img_lab.max() + 1e-8)
    
    thresholds = np.arange(0, 1, 1.0 / N_THRESHOLDS)[1:]
    bool_maps = []
    
    # Generate boolean maps by thresholding
    for thresh in thresholds:
        img_lab_T = img_lab.transpose(2,0,1)
        img_thresh = (img_lab_T > thresh)
        bool_maps.extend(list(img_thresh))

    # Compute attention map from boolean maps
    attn_map = np.zeros(img_lab.shape[:2], dtype=np.float32)
    for bmap in bool_maps:
        attn_map += _activate_boolean_map_helper(bmap)
    
    attn_map /= N_THRESHOLDS

    # Smoothing
    attn_map = cv2.GaussianBlur(attn_map, (0,0), 3)
    
    # Normalize result
    norm_val = np.sqrt((attn_map**2).sum())
    attn_map /= (norm_val + 1e-8)
    
    max_val = attn_map.max()
    if max_val > 0:
        attn_map /= max_val
        
    # Convert to 0-255 uint8
    attn_map_uint8 = (attn_map * 255).astype(np.uint8)

    # --- Post-processing: Hollow Filling ---
    if enable_fill:
        attn_map_uint8 = apply_hollow_filling(attn_map_uint8, kernel_size=7)

    return attn_map_uint8


